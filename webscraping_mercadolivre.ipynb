{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff5b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "\n",
    "# Creating variables for HTML tags and classes\n",
    "tags = ['span','span','span','a','li']\n",
    "classes = ['price-tag-fraction',\n",
    "           'ui-search-item__group__element ui-search-item__location',\n",
    "           'ui-search-item__group__element ui-search-item__subtitle',\n",
    "           'ui-search-result__content ui-search-link',\n",
    "           'ui-search-card-attributes__attribute']\n",
    "                   \n",
    "# Empty lists for storing the scrapped data\n",
    "a_size = len(classes)\n",
    "lists = [[] for i in range(a_size)]\n",
    "link = []\n",
    " \n",
    "# For loop to go through multiple pages and retrieve the data  \n",
    "pages = np.arange(1,50,48) # The second element of this array determines \"how far\" our for loop will go through the pages. \n",
    "                           # In this case I set it to a pretty low number (50) only for demonstration purposes.\n",
    "for page in pages:\n",
    "    page = requests.get(\"https://imoveis.mercadolivre.com.br/aluguel/_Desde_\"+str(page)+\"_NoIndex_True\")\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    sleep(randint(2,8))\n",
    "    house_data = soup.find_all('div',class_=\"ui-search-item__group ui-search-item__group--price\")\n",
    "    for i in range(a_size):\n",
    "        for data in soup.find_all(tags[i], class_=classes[i]):\n",
    "            if tags[i] == 'a':\n",
    "                lists[i].append(data['href'])\n",
    "            else:\n",
    "                lists[i].append(data.get_text())\n",
    "                                            \n",
    "## Creating Data Frames to treat the data ##      \n",
    "df = pd.DataFrame({'preços':lists[0],\n",
    "                   'localização':lists[1],\n",
    "                   'tipo':lists[2],\n",
    "                   'link':lists[3]})\n",
    "df_atc = pd.DataFrame({'atc':lists[4]})\n",
    "\n",
    "# House type\n",
    "df[['tipo_imovel','tipo_compra']] = df['tipo'].str.split('para',expand=True)\n",
    "df = df.drop(['tipo'], axis=1)  \n",
    "\n",
    "# Location\n",
    "df['uf'] = df['localização'].str.split(',').str[-1]\n",
    "df['cidade'] = df['localização'].str.split(',').str[-2]\n",
    "\n",
    "# Total area\n",
    "df_atc = df_atc[df_atc['atc'].str.contains('quarto')==False]  \n",
    "words_to_replace = {'m² construídos':'',\n",
    "                    'm² totais':''}\n",
    "for i, j in words_to_replace.items():\n",
    "    df_atc['atc'] = df_atc['atc'].str.replace(i, j)\n",
    "df_atc.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Exporting to a .xlsx file\n",
    "df = df.join(df_atc)\n",
    "df.to_excel('webscrapping_mercadolivre.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
